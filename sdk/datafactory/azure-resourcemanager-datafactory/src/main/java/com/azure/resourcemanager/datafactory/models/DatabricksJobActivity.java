// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) AutoRest Code Generator.

package com.azure.resourcemanager.datafactory.models;

import com.azure.core.annotation.Fluent;
import com.azure.core.util.logging.ClientLogger;
import com.azure.json.JsonReader;
import com.azure.json.JsonToken;
import com.azure.json.JsonWriter;
import com.azure.resourcemanager.datafactory.fluent.models.DatabricksJobActivityTypeProperties;
import java.io.IOException;
import java.util.LinkedHashMap;
import java.util.List;
import java.util.Map;

/**
 * Databricks Job activity.
 */
@Fluent
public final class DatabricksJobActivity extends ExecutionActivity {
    /*
     * Type of activity.
     */
    private String type = "DatabricksJob";

    /*
     * Databricks Job activity properties.
     */
    private DatabricksJobActivityTypeProperties innerTypeProperties = new DatabricksJobActivityTypeProperties();

    /**
     * Creates an instance of DatabricksJobActivity class.
     */
    public DatabricksJobActivity() {
    }

    /**
     * Get the type property: Type of activity.
     * 
     * @return the type value.
     */
    @Override
    public String type() {
        return this.type;
    }

    /**
     * Get the innerTypeProperties property: Databricks Job activity properties.
     * 
     * @return the innerTypeProperties value.
     */
    DatabricksJobActivityTypeProperties innerTypeProperties() {
        return this.innerTypeProperties;
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public DatabricksJobActivity withLinkedServiceName(LinkedServiceReference linkedServiceName) {
        super.withLinkedServiceName(linkedServiceName);
        return this;
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public DatabricksJobActivity withPolicy(ActivityPolicy policy) {
        super.withPolicy(policy);
        return this;
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public DatabricksJobActivity withName(String name) {
        super.withName(name);
        return this;
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public DatabricksJobActivity withDescription(String description) {
        super.withDescription(description);
        return this;
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public DatabricksJobActivity withState(ActivityState state) {
        super.withState(state);
        return this;
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public DatabricksJobActivity withOnInactiveMarkAs(ActivityOnInactiveMarkAs onInactiveMarkAs) {
        super.withOnInactiveMarkAs(onInactiveMarkAs);
        return this;
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public DatabricksJobActivity withDependsOn(List<ActivityDependency> dependsOn) {
        super.withDependsOn(dependsOn);
        return this;
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public DatabricksJobActivity withUserProperties(List<UserProperty> userProperties) {
        super.withUserProperties(userProperties);
        return this;
    }

    /**
     * Get the jobId property: The Id of the Databricks Job to be executed. Type: string (or Expression with resultType
     * string).
     * 
     * @return the jobId value.
     */
    public Object jobId() {
        return this.innerTypeProperties() == null ? null : this.innerTypeProperties().jobId();
    }

    /**
     * Set the jobId property: The Id of the Databricks Job to be executed. Type: string (or Expression with resultType
     * string).
     * 
     * @param jobId the jobId value to set.
     * @return the DatabricksJobActivity object itself.
     */
    public DatabricksJobActivity withJobId(Object jobId) {
        if (this.innerTypeProperties() == null) {
            this.innerTypeProperties = new DatabricksJobActivityTypeProperties();
        }
        this.innerTypeProperties().withJobId(jobId);
        return this;
    }

    /**
     * Get the jobParameters property: Job parameters to be used for each run of this job. If the job takes a parameter
     * that is not specified, the default value from the job will be used.
     * 
     * @return the jobParameters value.
     */
    public Map<String, Object> jobParameters() {
        return this.innerTypeProperties() == null ? null : this.innerTypeProperties().jobParameters();
    }

    /**
     * Set the jobParameters property: Job parameters to be used for each run of this job. If the job takes a parameter
     * that is not specified, the default value from the job will be used.
     * 
     * @param jobParameters the jobParameters value to set.
     * @return the DatabricksJobActivity object itself.
     */
    public DatabricksJobActivity withJobParameters(Map<String, Object> jobParameters) {
        if (this.innerTypeProperties() == null) {
            this.innerTypeProperties = new DatabricksJobActivityTypeProperties();
        }
        this.innerTypeProperties().withJobParameters(jobParameters);
        return this;
    }

    /**
     * Validates the instance.
     * 
     * @throws IllegalArgumentException thrown if the instance is not valid.
     */
    @Override
    public void validate() {
        if (innerTypeProperties() == null) {
            throw LOGGER.atError()
                .log(new IllegalArgumentException(
                    "Missing required property innerTypeProperties in model DatabricksJobActivity"));
        } else {
            innerTypeProperties().validate();
        }
        if (name() == null) {
            throw LOGGER.atError()
                .log(new IllegalArgumentException("Missing required property name in model DatabricksJobActivity"));
        }
        if (dependsOn() != null) {
            dependsOn().forEach(e -> e.validate());
        }
        if (userProperties() != null) {
            userProperties().forEach(e -> e.validate());
        }
        if (linkedServiceName() != null) {
            linkedServiceName().validate();
        }
        if (policy() != null) {
            policy().validate();
        }
    }

    private static final ClientLogger LOGGER = new ClientLogger(DatabricksJobActivity.class);

    /**
     * {@inheritDoc}
     */
    @Override
    public JsonWriter toJson(JsonWriter jsonWriter) throws IOException {
        jsonWriter.writeStartObject();
        jsonWriter.writeStringField("name", name());
        jsonWriter.writeStringField("description", description());
        jsonWriter.writeStringField("state", state() == null ? null : state().toString());
        jsonWriter.writeStringField("onInactiveMarkAs",
            onInactiveMarkAs() == null ? null : onInactiveMarkAs().toString());
        jsonWriter.writeArrayField("dependsOn", dependsOn(), (writer, element) -> writer.writeJson(element));
        jsonWriter.writeArrayField("userProperties", userProperties(), (writer, element) -> writer.writeJson(element));
        jsonWriter.writeJsonField("linkedServiceName", linkedServiceName());
        jsonWriter.writeJsonField("policy", policy());
        jsonWriter.writeJsonField("typeProperties", this.innerTypeProperties);
        jsonWriter.writeStringField("type", this.type);
        if (additionalProperties() != null) {
            for (Map.Entry<String, Object> additionalProperty : additionalProperties().entrySet()) {
                jsonWriter.writeUntypedField(additionalProperty.getKey(), additionalProperty.getValue());
            }
        }
        return jsonWriter.writeEndObject();
    }

    /**
     * Reads an instance of DatabricksJobActivity from the JsonReader.
     * 
     * @param jsonReader The JsonReader being read.
     * @return An instance of DatabricksJobActivity if the JsonReader was pointing to an instance of it, or null if it
     * was pointing to JSON null.
     * @throws IllegalStateException If the deserialized JSON object was missing any required properties.
     * @throws IOException If an error occurs while reading the DatabricksJobActivity.
     */
    public static DatabricksJobActivity fromJson(JsonReader jsonReader) throws IOException {
        return jsonReader.readObject(reader -> {
            DatabricksJobActivity deserializedDatabricksJobActivity = new DatabricksJobActivity();
            Map<String, Object> additionalProperties = null;
            while (reader.nextToken() != JsonToken.END_OBJECT) {
                String fieldName = reader.getFieldName();
                reader.nextToken();

                if ("name".equals(fieldName)) {
                    deserializedDatabricksJobActivity.withName(reader.getString());
                } else if ("description".equals(fieldName)) {
                    deserializedDatabricksJobActivity.withDescription(reader.getString());
                } else if ("state".equals(fieldName)) {
                    deserializedDatabricksJobActivity.withState(ActivityState.fromString(reader.getString()));
                } else if ("onInactiveMarkAs".equals(fieldName)) {
                    deserializedDatabricksJobActivity
                        .withOnInactiveMarkAs(ActivityOnInactiveMarkAs.fromString(reader.getString()));
                } else if ("dependsOn".equals(fieldName)) {
                    List<ActivityDependency> dependsOn
                        = reader.readArray(reader1 -> ActivityDependency.fromJson(reader1));
                    deserializedDatabricksJobActivity.withDependsOn(dependsOn);
                } else if ("userProperties".equals(fieldName)) {
                    List<UserProperty> userProperties = reader.readArray(reader1 -> UserProperty.fromJson(reader1));
                    deserializedDatabricksJobActivity.withUserProperties(userProperties);
                } else if ("linkedServiceName".equals(fieldName)) {
                    deserializedDatabricksJobActivity.withLinkedServiceName(LinkedServiceReference.fromJson(reader));
                } else if ("policy".equals(fieldName)) {
                    deserializedDatabricksJobActivity.withPolicy(ActivityPolicy.fromJson(reader));
                } else if ("typeProperties".equals(fieldName)) {
                    deserializedDatabricksJobActivity.innerTypeProperties
                        = DatabricksJobActivityTypeProperties.fromJson(reader);
                } else if ("type".equals(fieldName)) {
                    deserializedDatabricksJobActivity.type = reader.getString();
                } else {
                    if (additionalProperties == null) {
                        additionalProperties = new LinkedHashMap<>();
                    }

                    additionalProperties.put(fieldName, reader.readUntyped());
                }
            }
            deserializedDatabricksJobActivity.withAdditionalProperties(additionalProperties);

            return deserializedDatabricksJobActivity;
        });
    }
}
