// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) AutoRest Code Generator.

package com.azure.resourcemanager.machinelearning.models;

import com.azure.core.annotation.Fluent;
import com.azure.core.management.exception.ManagementError;
import com.azure.core.util.CoreUtils;
import com.azure.json.JsonReader;
import com.azure.json.JsonToken;
import com.azure.json.JsonWriter;
import java.io.IOException;
import java.util.List;

/**
 * A DataFactory compute.
 */
@Fluent
public final class Databricks extends Compute {
    /*
     * The type of compute
     */
    private ComputeType computeType = ComputeType.DATABRICKS;

    /*
     * Properties of Databricks
     */
    private DatabricksProperties properties;

    /**
     * Creates an instance of Databricks class.
     */
    public Databricks() {
    }

    /**
     * Get the computeType property: The type of compute.
     * 
     * @return the computeType value.
     */
    @Override
    public ComputeType computeType() {
        return this.computeType;
    }

    /**
     * Get the properties property: Properties of Databricks.
     * 
     * @return the properties value.
     */
    public DatabricksProperties properties() {
        return this.properties;
    }

    /**
     * Set the properties property: Properties of Databricks.
     * 
     * @param properties the properties value to set.
     * @return the Databricks object itself.
     */
    public Databricks withProperties(DatabricksProperties properties) {
        this.properties = properties;
        return this;
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public Databricks withComputeLocation(String computeLocation) {
        super.withComputeLocation(computeLocation);
        return this;
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public Databricks withDescription(String description) {
        super.withDescription(description);
        return this;
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public Databricks withResourceId(String resourceId) {
        super.withResourceId(resourceId);
        return this;
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public Databricks withDisableLocalAuth(Boolean disableLocalAuth) {
        super.withDisableLocalAuth(disableLocalAuth);
        return this;
    }

    /**
     * Validates the instance.
     * 
     * @throws IllegalArgumentException thrown if the instance is not valid.
     */
    @Override
    public void validate() {
        if (properties() != null) {
            properties().validate();
        }
    }

    /**
     * {@inheritDoc}
     */
    @Override
    public JsonWriter toJson(JsonWriter jsonWriter) throws IOException {
        jsonWriter.writeStartObject();
        jsonWriter.writeStringField("computeLocation", computeLocation());
        jsonWriter.writeStringField("description", description());
        jsonWriter.writeStringField("resourceId", resourceId());
        jsonWriter.writeBooleanField("disableLocalAuth", disableLocalAuth());
        jsonWriter.writeStringField("computeType", this.computeType == null ? null : this.computeType.toString());
        jsonWriter.writeJsonField("properties", this.properties);
        return jsonWriter.writeEndObject();
    }

    /**
     * Reads an instance of Databricks from the JsonReader.
     * 
     * @param jsonReader The JsonReader being read.
     * @return An instance of Databricks if the JsonReader was pointing to an instance of it, or null if it was pointing
     * to JSON null.
     * @throws IOException If an error occurs while reading the Databricks.
     */
    public static Databricks fromJson(JsonReader jsonReader) throws IOException {
        return jsonReader.readObject(reader -> {
            Databricks deserializedDatabricks = new Databricks();
            while (reader.nextToken() != JsonToken.END_OBJECT) {
                String fieldName = reader.getFieldName();
                reader.nextToken();

                if ("computeLocation".equals(fieldName)) {
                    deserializedDatabricks.withComputeLocation(reader.getString());
                } else if ("provisioningState".equals(fieldName)) {
                    deserializedDatabricks.withProvisioningState(ProvisioningState.fromString(reader.getString()));
                } else if ("description".equals(fieldName)) {
                    deserializedDatabricks.withDescription(reader.getString());
                } else if ("createdOn".equals(fieldName)) {
                    deserializedDatabricks.withCreatedOn(reader
                        .getNullable(nonNullReader -> CoreUtils.parseBestOffsetDateTime(nonNullReader.getString())));
                } else if ("modifiedOn".equals(fieldName)) {
                    deserializedDatabricks.withModifiedOn(reader
                        .getNullable(nonNullReader -> CoreUtils.parseBestOffsetDateTime(nonNullReader.getString())));
                } else if ("resourceId".equals(fieldName)) {
                    deserializedDatabricks.withResourceId(reader.getString());
                } else if ("provisioningErrors".equals(fieldName)) {
                    List<ManagementError> provisioningErrors
                        = reader.readArray(reader1 -> ManagementError.fromJson(reader1));
                    deserializedDatabricks.withProvisioningErrors(provisioningErrors);
                } else if ("isAttachedCompute".equals(fieldName)) {
                    deserializedDatabricks.withIsAttachedCompute(reader.getNullable(JsonReader::getBoolean));
                } else if ("disableLocalAuth".equals(fieldName)) {
                    deserializedDatabricks.withDisableLocalAuth(reader.getNullable(JsonReader::getBoolean));
                } else if ("computeType".equals(fieldName)) {
                    deserializedDatabricks.computeType = ComputeType.fromString(reader.getString());
                } else if ("properties".equals(fieldName)) {
                    deserializedDatabricks.properties = DatabricksProperties.fromJson(reader);
                } else {
                    reader.skipChildren();
                }
            }

            return deserializedDatabricks;
        });
    }
}
