// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) AutoRest Code Generator.

package com.azure.resourcemanager.machinelearning.models;

import com.azure.core.annotation.Fluent;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonTypeId;
import com.fasterxml.jackson.annotation.JsonTypeInfo;
import com.fasterxml.jackson.annotation.JsonTypeName;

/**
 * Triton inferencing server configurations.
 */
@JsonTypeInfo(
    use = JsonTypeInfo.Id.NAME,
    property = "serverType",
    defaultImpl = TritonInferencingServer.class,
    visible = true)
@JsonTypeName("Triton")
@Fluent
public final class TritonInferencingServer extends InferencingServer {
    /*
     * [Required] Inferencing server type for various targets.
     */
    @JsonTypeId
    @JsonProperty(value = "serverType", required = true)
    private InferencingServerType serverType = InferencingServerType.TRITON;

    /*
     * Inference configuration for Triton.
     */
    @JsonProperty(value = "inferenceConfiguration")
    private OnlineInferenceConfiguration inferenceConfiguration;

    /**
     * Creates an instance of TritonInferencingServer class.
     */
    public TritonInferencingServer() {
    }

    /**
     * Get the serverType property: [Required] Inferencing server type for various targets.
     * 
     * @return the serverType value.
     */
    @Override
    public InferencingServerType serverType() {
        return this.serverType;
    }

    /**
     * Get the inferenceConfiguration property: Inference configuration for Triton.
     * 
     * @return the inferenceConfiguration value.
     */
    public OnlineInferenceConfiguration inferenceConfiguration() {
        return this.inferenceConfiguration;
    }

    /**
     * Set the inferenceConfiguration property: Inference configuration for Triton.
     * 
     * @param inferenceConfiguration the inferenceConfiguration value to set.
     * @return the TritonInferencingServer object itself.
     */
    public TritonInferencingServer withInferenceConfiguration(OnlineInferenceConfiguration inferenceConfiguration) {
        this.inferenceConfiguration = inferenceConfiguration;
        return this;
    }

    /**
     * Validates the instance.
     * 
     * @throws IllegalArgumentException thrown if the instance is not valid.
     */
    @Override
    public void validate() {
        super.validate();
        if (inferenceConfiguration() != null) {
            inferenceConfiguration().validate();
        }
    }
}
