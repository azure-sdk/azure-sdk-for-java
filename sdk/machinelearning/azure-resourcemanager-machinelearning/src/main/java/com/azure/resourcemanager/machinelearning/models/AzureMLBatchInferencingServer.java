// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) AutoRest Code Generator.

package com.azure.resourcemanager.machinelearning.models;

import com.azure.core.annotation.Fluent;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonTypeId;
import com.fasterxml.jackson.annotation.JsonTypeInfo;
import com.fasterxml.jackson.annotation.JsonTypeName;

/**
 * Azure ML batch inferencing server configurations.
 */
@JsonTypeInfo(
    use = JsonTypeInfo.Id.NAME,
    property = "serverType",
    defaultImpl = AzureMLBatchInferencingServer.class,
    visible = true)
@JsonTypeName("AzureMLBatch")
@Fluent
public final class AzureMLBatchInferencingServer extends InferencingServer {
    /*
     * [Required] Inferencing server type for various targets.
     */
    @JsonTypeId
    @JsonProperty(value = "serverType", required = true)
    private InferencingServerType serverType = InferencingServerType.AZURE_MLBATCH;

    /*
     * Code configuration for AML batch inferencing server.
     */
    @JsonProperty(value = "codeConfiguration")
    private CodeConfiguration codeConfiguration;

    /**
     * Creates an instance of AzureMLBatchInferencingServer class.
     */
    public AzureMLBatchInferencingServer() {
    }

    /**
     * Get the serverType property: [Required] Inferencing server type for various targets.
     * 
     * @return the serverType value.
     */
    @Override
    public InferencingServerType serverType() {
        return this.serverType;
    }

    /**
     * Get the codeConfiguration property: Code configuration for AML batch inferencing server.
     * 
     * @return the codeConfiguration value.
     */
    public CodeConfiguration codeConfiguration() {
        return this.codeConfiguration;
    }

    /**
     * Set the codeConfiguration property: Code configuration for AML batch inferencing server.
     * 
     * @param codeConfiguration the codeConfiguration value to set.
     * @return the AzureMLBatchInferencingServer object itself.
     */
    public AzureMLBatchInferencingServer withCodeConfiguration(CodeConfiguration codeConfiguration) {
        this.codeConfiguration = codeConfiguration;
        return this;
    }

    /**
     * Validates the instance.
     * 
     * @throws IllegalArgumentException thrown if the instance is not valid.
     */
    @Override
    public void validate() {
        super.validate();
        if (codeConfiguration() != null) {
            codeConfiguration().validate();
        }
    }
}
