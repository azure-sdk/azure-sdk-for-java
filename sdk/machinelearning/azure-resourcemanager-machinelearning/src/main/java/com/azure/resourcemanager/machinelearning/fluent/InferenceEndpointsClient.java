// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) AutoRest Code Generator.

package com.azure.resourcemanager.machinelearning.fluent;

import com.azure.core.annotation.ReturnType;
import com.azure.core.annotation.ServiceMethod;
import com.azure.core.http.rest.PagedIterable;
import com.azure.core.http.rest.Response;
import com.azure.core.management.polling.PollResult;
import com.azure.core.util.Context;
import com.azure.core.util.polling.SyncPoller;
import com.azure.resourcemanager.machinelearning.fluent.models.InferenceEndpointInner;
import com.azure.resourcemanager.machinelearning.models.OrderString;

/** An instance of this class provides access to all the operations defined in InferenceEndpointsClient. */
public interface InferenceEndpointsClient {
    /**
     * List Inference Endpoints.
     *
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param poolName Name of the InferencePool.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return a paginated list of InferenceEndpoint entities as paginated response with {@link PagedIterable}.
     */
    @ServiceMethod(returns = ReturnType.COLLECTION)
    PagedIterable<InferenceEndpointInner> list(String resourceGroupName, String workspaceName, String poolName);

    /**
     * List Inference Endpoints.
     *
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param poolName Name of the InferencePool.
     * @param count Number of InferenceEndpoint to be retrieved in a page of results.
     * @param skip Continuation token for pagination.
     * @param tags A set of tags with which to filter the returned models. It is a comma separated string of tags key or
     *     tags key=value. Example: tagKey1,tagKey2,tagKey3=value3 .
     * @param properties A set of properties with which to filter the returned models. It is a comma separated string of
     *     properties key and/or properties key=value Example: propKey1,propKey2,propKey3=value3 .
     * @param orderBy The option to order the response.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return a paginated list of InferenceEndpoint entities as paginated response with {@link PagedIterable}.
     */
    @ServiceMethod(returns = ReturnType.COLLECTION)
    PagedIterable<InferenceEndpointInner> list(
        String resourceGroupName,
        String workspaceName,
        String poolName,
        Integer count,
        String skip,
        String tags,
        String properties,
        OrderString orderBy,
        Context context);

    /**
     * Delete InferenceEndpoint (asynchronous).
     *
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param poolName InferencePool name.
     * @param endpointName InferenceEndpoint name.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the {@link SyncPoller} for polling of long-running operation.
     */
    @ServiceMethod(returns = ReturnType.LONG_RUNNING_OPERATION)
    SyncPoller<PollResult<Void>, Void> beginDelete(
        String resourceGroupName, String workspaceName, String poolName, String endpointName);

    /**
     * Delete InferenceEndpoint (asynchronous).
     *
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param poolName InferencePool name.
     * @param endpointName InferenceEndpoint name.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the {@link SyncPoller} for polling of long-running operation.
     */
    @ServiceMethod(returns = ReturnType.LONG_RUNNING_OPERATION)
    SyncPoller<PollResult<Void>, Void> beginDelete(
        String resourceGroupName, String workspaceName, String poolName, String endpointName, Context context);

    /**
     * Delete InferenceEndpoint (asynchronous).
     *
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param poolName InferencePool name.
     * @param endpointName InferenceEndpoint name.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    void delete(String resourceGroupName, String workspaceName, String poolName, String endpointName);

    /**
     * Delete InferenceEndpoint (asynchronous).
     *
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param poolName InferencePool name.
     * @param endpointName InferenceEndpoint name.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    void delete(String resourceGroupName, String workspaceName, String poolName, String endpointName, Context context);

    /**
     * Get InferenceEndpoint.
     *
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param poolName InferencePool name.
     * @param endpointName InferenceEndpoint name.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return inferenceEndpoint along with {@link Response}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    Response<InferenceEndpointInner> getWithResponse(
        String resourceGroupName, String workspaceName, String poolName, String endpointName, Context context);

    /**
     * Get InferenceEndpoint.
     *
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param poolName InferencePool name.
     * @param endpointName InferenceEndpoint name.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return inferenceEndpoint.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    InferenceEndpointInner get(String resourceGroupName, String workspaceName, String poolName, String endpointName);

    /**
     * Update InferenceEndpoint (asynchronous).
     *
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param poolName InferencePool name.
     * @param endpointName InferenceEndpoint name.
     * @param body Online Endpoint entity to apply during operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the {@link SyncPoller} for polling of long-running operation.
     */
    @ServiceMethod(returns = ReturnType.LONG_RUNNING_OPERATION)
    SyncPoller<PollResult<InferenceEndpointInner>, InferenceEndpointInner> beginUpdate(
        String resourceGroupName, String workspaceName, String poolName, String endpointName, Object body);

    /**
     * Update InferenceEndpoint (asynchronous).
     *
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param poolName InferencePool name.
     * @param endpointName InferenceEndpoint name.
     * @param body Online Endpoint entity to apply during operation.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the {@link SyncPoller} for polling of long-running operation.
     */
    @ServiceMethod(returns = ReturnType.LONG_RUNNING_OPERATION)
    SyncPoller<PollResult<InferenceEndpointInner>, InferenceEndpointInner> beginUpdate(
        String resourceGroupName,
        String workspaceName,
        String poolName,
        String endpointName,
        Object body,
        Context context);

    /**
     * Update InferenceEndpoint (asynchronous).
     *
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param poolName InferencePool name.
     * @param endpointName InferenceEndpoint name.
     * @param body Online Endpoint entity to apply during operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    InferenceEndpointInner update(
        String resourceGroupName, String workspaceName, String poolName, String endpointName, Object body);

    /**
     * Update InferenceEndpoint (asynchronous).
     *
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param poolName InferencePool name.
     * @param endpointName InferenceEndpoint name.
     * @param body Online Endpoint entity to apply during operation.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    InferenceEndpointInner update(
        String resourceGroupName,
        String workspaceName,
        String poolName,
        String endpointName,
        Object body,
        Context context);

    /**
     * Create or update InferenceEndpoint (asynchronous).
     *
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param poolName InferencePool name.
     * @param endpointName InferenceEndpoint name.
     * @param body InferenceEndpoint entity to apply during operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the {@link SyncPoller} for polling of long-running operation.
     */
    @ServiceMethod(returns = ReturnType.LONG_RUNNING_OPERATION)
    SyncPoller<PollResult<InferenceEndpointInner>, InferenceEndpointInner> beginCreateOrUpdate(
        String resourceGroupName,
        String workspaceName,
        String poolName,
        String endpointName,
        InferenceEndpointInner body);

    /**
     * Create or update InferenceEndpoint (asynchronous).
     *
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param poolName InferencePool name.
     * @param endpointName InferenceEndpoint name.
     * @param body InferenceEndpoint entity to apply during operation.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the {@link SyncPoller} for polling of long-running operation.
     */
    @ServiceMethod(returns = ReturnType.LONG_RUNNING_OPERATION)
    SyncPoller<PollResult<InferenceEndpointInner>, InferenceEndpointInner> beginCreateOrUpdate(
        String resourceGroupName,
        String workspaceName,
        String poolName,
        String endpointName,
        InferenceEndpointInner body,
        Context context);

    /**
     * Create or update InferenceEndpoint (asynchronous).
     *
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param poolName InferencePool name.
     * @param endpointName InferenceEndpoint name.
     * @param body InferenceEndpoint entity to apply during operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    InferenceEndpointInner createOrUpdate(
        String resourceGroupName,
        String workspaceName,
        String poolName,
        String endpointName,
        InferenceEndpointInner body);

    /**
     * Create or update InferenceEndpoint (asynchronous).
     *
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param poolName InferencePool name.
     * @param endpointName InferenceEndpoint name.
     * @param body InferenceEndpoint entity to apply during operation.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    InferenceEndpointInner createOrUpdate(
        String resourceGroupName,
        String workspaceName,
        String poolName,
        String endpointName,
        InferenceEndpointInner body,
        Context context);
}
