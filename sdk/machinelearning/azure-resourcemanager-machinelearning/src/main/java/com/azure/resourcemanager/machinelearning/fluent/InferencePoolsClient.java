// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) AutoRest Code Generator.

package com.azure.resourcemanager.machinelearning.fluent;

import com.azure.core.annotation.ReturnType;
import com.azure.core.annotation.ServiceMethod;
import com.azure.core.http.rest.PagedIterable;
import com.azure.core.http.rest.Response;
import com.azure.core.management.polling.PollResult;
import com.azure.core.util.Context;
import com.azure.core.util.polling.SyncPoller;
import com.azure.resourcemanager.machinelearning.fluent.models.InferencePoolInner;
import com.azure.resourcemanager.machinelearning.fluent.models.PoolStatusInner;
import com.azure.resourcemanager.machinelearning.fluent.models.SkuResourceInner;
import com.azure.resourcemanager.machinelearning.models.OrderString;
import com.azure.resourcemanager.machinelearning.models.PartialMinimalTrackedResourceWithSkuAndIdentity;

/**
 * An instance of this class provides access to all the operations defined in InferencePoolsClient.
 */
public interface InferencePoolsClient {
    /**
     * List InferencePools.
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return a paginated list of InferencePool entities as paginated response with {@link PagedIterable}.
     */
    @ServiceMethod(returns = ReturnType.COLLECTION)
    PagedIterable<InferencePoolInner> list(String resourceGroupName, String workspaceName);

    /**
     * List InferencePools.
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param count Number of inferencePools to be retrieved in a page of results.
     * @param skip Continuation token for pagination.
     * @param tags A set of tags with which to filter the returned models. It is a comma separated string of tags key or
     * tags key=value. Example: tagKey1,tagKey2,tagKey3=value3 .
     * @param properties A set of properties with which to filter the returned models. It is a comma separated string of
     * properties key and/or properties key=value Example: propKey1,propKey2,propKey3=value3 .
     * @param orderBy The option to order the response.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return a paginated list of InferencePool entities as paginated response with {@link PagedIterable}.
     */
    @ServiceMethod(returns = ReturnType.COLLECTION)
    PagedIterable<InferencePoolInner> list(String resourceGroupName, String workspaceName, Integer count, String skip,
        String tags, String properties, OrderString orderBy, Context context);

    /**
     * Delete InferencePool (asynchronous).
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param inferencePoolName Name of InferencePool.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the {@link SyncPoller} for polling of long-running operation.
     */
    @ServiceMethod(returns = ReturnType.LONG_RUNNING_OPERATION)
    SyncPoller<PollResult<Void>, Void> beginDelete(String resourceGroupName, String workspaceName,
        String inferencePoolName);

    /**
     * Delete InferencePool (asynchronous).
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param inferencePoolName Name of InferencePool.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the {@link SyncPoller} for polling of long-running operation.
     */
    @ServiceMethod(returns = ReturnType.LONG_RUNNING_OPERATION)
    SyncPoller<PollResult<Void>, Void> beginDelete(String resourceGroupName, String workspaceName,
        String inferencePoolName, Context context);

    /**
     * Delete InferencePool (asynchronous).
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param inferencePoolName Name of InferencePool.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    void delete(String resourceGroupName, String workspaceName, String inferencePoolName);

    /**
     * Delete InferencePool (asynchronous).
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param inferencePoolName Name of InferencePool.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    void delete(String resourceGroupName, String workspaceName, String inferencePoolName, Context context);

    /**
     * Get InferencePool.
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param inferencePoolName Name of InferencePool.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return inferencePool along with {@link Response}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    Response<InferencePoolInner> getWithResponse(String resourceGroupName, String workspaceName,
        String inferencePoolName, Context context);

    /**
     * Get InferencePool.
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param inferencePoolName Name of InferencePool.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return inferencePool.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    InferencePoolInner get(String resourceGroupName, String workspaceName, String inferencePoolName);

    /**
     * Update InferencePool (asynchronous).
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param inferencePoolName Name of InferencePool.
     * @param body Inference Pool entity to apply during operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the {@link SyncPoller} for polling of long-running operation.
     */
    @ServiceMethod(returns = ReturnType.LONG_RUNNING_OPERATION)
    SyncPoller<PollResult<InferencePoolInner>, InferencePoolInner> beginUpdate(String resourceGroupName,
        String workspaceName, String inferencePoolName, PartialMinimalTrackedResourceWithSkuAndIdentity body);

    /**
     * Update InferencePool (asynchronous).
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param inferencePoolName Name of InferencePool.
     * @param body Inference Pool entity to apply during operation.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the {@link SyncPoller} for polling of long-running operation.
     */
    @ServiceMethod(returns = ReturnType.LONG_RUNNING_OPERATION)
    SyncPoller<PollResult<InferencePoolInner>, InferencePoolInner> beginUpdate(String resourceGroupName,
        String workspaceName, String inferencePoolName, PartialMinimalTrackedResourceWithSkuAndIdentity body,
        Context context);

    /**
     * Update InferencePool (asynchronous).
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param inferencePoolName Name of InferencePool.
     * @param body Inference Pool entity to apply during operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    InferencePoolInner update(String resourceGroupName, String workspaceName, String inferencePoolName,
        PartialMinimalTrackedResourceWithSkuAndIdentity body);

    /**
     * Update InferencePool (asynchronous).
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param inferencePoolName Name of InferencePool.
     * @param body Inference Pool entity to apply during operation.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    InferencePoolInner update(String resourceGroupName, String workspaceName, String inferencePoolName,
        PartialMinimalTrackedResourceWithSkuAndIdentity body, Context context);

    /**
     * Create or update InferencePool (asynchronous).
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param inferencePoolName Name of InferencePool.
     * @param body InferencePool entity to apply during operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the {@link SyncPoller} for polling of long-running operation.
     */
    @ServiceMethod(returns = ReturnType.LONG_RUNNING_OPERATION)
    SyncPoller<PollResult<InferencePoolInner>, InferencePoolInner> beginCreateOrUpdate(String resourceGroupName,
        String workspaceName, String inferencePoolName, InferencePoolInner body);

    /**
     * Create or update InferencePool (asynchronous).
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param inferencePoolName Name of InferencePool.
     * @param body InferencePool entity to apply during operation.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the {@link SyncPoller} for polling of long-running operation.
     */
    @ServiceMethod(returns = ReturnType.LONG_RUNNING_OPERATION)
    SyncPoller<PollResult<InferencePoolInner>, InferencePoolInner> beginCreateOrUpdate(String resourceGroupName,
        String workspaceName, String inferencePoolName, InferencePoolInner body, Context context);

    /**
     * Create or update InferencePool (asynchronous).
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param inferencePoolName Name of InferencePool.
     * @param body InferencePool entity to apply during operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    InferencePoolInner createOrUpdate(String resourceGroupName, String workspaceName, String inferencePoolName,
        InferencePoolInner body);

    /**
     * Create or update InferencePool (asynchronous).
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param inferencePoolName Name of InferencePool.
     * @param body InferencePool entity to apply during operation.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    InferencePoolInner createOrUpdate(String resourceGroupName, String workspaceName, String inferencePoolName,
        InferencePoolInner body, Context context);

    /**
     * Retrieve inference pool status.
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param inferencePoolName Name of InferencePool.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response body along with {@link Response}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    Response<PoolStatusInner> getStatusWithResponse(String resourceGroupName, String workspaceName,
        String inferencePoolName, Context context);

    /**
     * Retrieve inference pool status.
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param inferencePoolName Name of InferencePool.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    PoolStatusInner getStatus(String resourceGroupName, String workspaceName, String inferencePoolName);

    /**
     * List Inference Pool Skus.
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param inferencePoolName Inference Group name.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return a paginated list of SkuResource entities as paginated response with {@link PagedIterable}.
     */
    @ServiceMethod(returns = ReturnType.COLLECTION)
    PagedIterable<SkuResourceInner> listSkus(String resourceGroupName, String workspaceName, String inferencePoolName);

    /**
     * List Inference Pool Skus.
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Name of Azure Machine Learning workspace.
     * @param inferencePoolName Inference Group name.
     * @param count Number of Skus to be retrieved in a page of results.
     * @param skip Continuation token for pagination.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return a paginated list of SkuResource entities as paginated response with {@link PagedIterable}.
     */
    @ServiceMethod(returns = ReturnType.COLLECTION)
    PagedIterable<SkuResourceInner> listSkus(String resourceGroupName, String workspaceName, String inferencePoolName,
        Integer count, String skip, Context context);
}
